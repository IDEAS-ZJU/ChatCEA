{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for subprocess, concurrent tasks, and PDF processing\n",
    "import subprocess\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from tqdm import tqdm  # For progress bars\n",
    "from PyPDF2 import PdfReader  # For handling PDF files\n",
    "import fitz  # Import PyMuPDF\n",
    "import base64  # Import base64 for image encoding\n",
    "\n",
    "# Importing LangChain specific components for document processing and retrieval\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever, SearchType\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from BCEmbedding import RerankerModel\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, SystemMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45932c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def june_run_nougat(file_path, output_dir):\n",
    "    \"\"\"\n",
    "    Run Nougat tool on the given file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input PDF file.\n",
    "        output_dir (str): Directory to store the output.\n",
    "\n",
    "    Returns:\n",
    "        int: 0 if operation is successful, 1 if failed.\n",
    "    \"\"\"\n",
    "    cmd = [\"nougat.exe\", file_path, \"-o\", output_dir, \"-m\", \"0.1.0-base\", \"--no-skipping\"]\n",
    "    res = subprocess.run(cmd)\n",
    "    \n",
    "    if res.returncode != 0:\n",
    "        print(f\"Error when running Nougat on {file_path}.\")\n",
    "        return res.returncode\n",
    "    else:\n",
    "        print(f\"Operation completed for {file_path}!\")\n",
    "        return 0\n",
    "\n",
    "def june_get_tables_from_mmd(mmd_path):\n",
    "    \"\"\"\n",
    "    Extract tables from an MMD file generated by Nougat.\n",
    "\n",
    "    Args:\n",
    "        mmd_path (str): Path to the MMD file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tables extracted from the MMD file.\n",
    "    \"\"\"\n",
    "    with open(mmd_path, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    res = []\n",
    "    tmp = []\n",
    "    flag = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if line == \"\\\\begin{table}\\n\":\n",
    "            flag = \"BEGINTABLE\"\n",
    "        elif line == \"\\\\end{table}\\n\":\n",
    "            flag = \"ENDTABLE\"\n",
    "        \n",
    "        if flag == \"BEGINTABLE\":\n",
    "            tmp.append(line)\n",
    "        elif flag == \"ENDTABLE\":\n",
    "            tmp.append(line)\n",
    "            flag = \"CAPTION\"\n",
    "        elif flag == \"CAPTION\":\n",
    "            tmp.append(line)\n",
    "            flag = \"MARKDOWN\"\n",
    "            res.append(''.join(tmp))\n",
    "            tmp = []\n",
    "    \n",
    "    return res\n",
    "\n",
    "def process_pdf(file_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a PDF file by extracting text, tables, and images, and run Nougat tool.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input PDF file.\n",
    "        output_dir (str): Directory to store the output.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (texts_with_metadata, tables_with_metadata, images_with_metadata, pdf_id, elapsed_time)\n",
    "            - texts_with_metadata: List of documents containing the extracted text.\n",
    "            - tables_with_metadata: List of documents containing the extracted tables.\n",
    "            - images_with_metadata: List of documents containing extracted image base64 URIs.\n",
    "            - pdf_id: Unique identifier for the PDF file.\n",
    "            - elapsed_time: Time taken to process the PDF.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    pdf_id = str(uuid.uuid4())\n",
    "    texts_with_metadata = []\n",
    "    tables_with_metadata = []\n",
    "    images_with_metadata = [] \n",
    "\n",
    "    # Load PDF and extract text\n",
    "    reader = PdfReader(file_path)\n",
    "    pages = []\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            pages.append(Document(page_content=page_text, metadata={\"pdf_id\": pdf_id}))\n",
    "\n",
    "    # Split text using NLTKTextSplitter\n",
    "    text_splitter = NLTKTextSplitter()\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "\n",
    "    # Add PDF ID to each text document's metadata\n",
    "    texts_with_metadata.extend([Document(page_content=text.page_content, metadata={\"pdf_id\": pdf_id}) for text in texts])\n",
    "\n",
    "    # --- Ekstraksi Gambar Baru ---\n",
    "    try:\n",
    "        doc = fitz.open(file_path)\n",
    "        for page_num in range(len(doc)):\n",
    "            page_images = doc.load_page(page_num).get_images(full=True)\n",
    "            for img_index, img in enumerate(page_images):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                \n",
    "                # Encode as base64\n",
    "                img_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                img_uri = f\"data:image/{image_ext};base64,{img_base64}\"\n",
    "                \n",
    "                images_with_metadata.append(Document(\n",
    "                    page_content=img_uri, \n",
    "                    metadata={\"pdf_id\": pdf_id, \"type\": \"image\", \"page\": page_num}\n",
    "                ))\n",
    "        doc.close()\n",
    "        print(f\"Extracted {len(images_with_metadata)} images from {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from {file_path}: {e}\")\n",
    "    # --- Akhir Ekstraksi Gambar ---\n",
    "\n",
    "    # Run Nougat tool\n",
    "    if june_run_nougat(file_path, output_dir) == 1:\n",
    "        print(f\"Failed to process {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract tables from MMD file generated by Nougat\n",
    "    mmd_path = os.path.join(output_dir, os.path.splitext(os.path.basename(file_path))[0] + \".mmd\")\n",
    "    tables = june_get_tables_from_mmd(mmd_path)\n",
    "    tables_with_metadata.extend([Document(page_content=table, metadata={\"pdf_id\": pdf_id}) for table in tables])\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Processed {file_path} in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Perbarui nilai return\n",
    "    return texts_with_metadata, tables_with_metadata, images_with_metadata, pdf_id, elapsed_time\n",
    "\n",
    "def process_pdfs_in_batches(input_dir, output_dir, batch_size=10, max_workers=4):\n",
    "    \"\"\"\n",
    "    Process multiple PDFs in batches with parallel execution.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Directory containing PDF files.\n",
    "        output_dir (str): Directory to store the output.\n",
    "        batch_size (int): Number of PDFs to process in each batch.\n",
    "        max_workers (int): Maximum number of concurrent workers.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (all_texts, all_tables, all_images, pdf_ids, processing_times)\n",
    "            - all_texts: List of all extracted texts from PDFs.\n",
    "            - all_tables: List of all extracted tables from PDFs.\n",
    "            - all_images: List of all extracted images from PDFs.\n",
    "            - pdf_ids: List of unique PDF IDs.\n",
    "            - processing_times: List of processing times for each PDF.\n",
    "    \"\"\"\n",
    "    pdf_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.pdf')]\n",
    "    \n",
    "    all_texts = []\n",
    "    all_tables = []\n",
    "    all_images = [] # <-- List baru untuk gambar\n",
    "    pdf_ids = []\n",
    "    processing_times = []\n",
    "\n",
    "    for i in range(0, len(pdf_files), batch_size):\n",
    "        batch_files = pdf_files[i:i + batch_size]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(process_pdf, pdf_file, output_dir) for pdf_file in batch_files]\n",
    "\n",
    "            # Show progress using tqdm\n",
    "            for future in tqdm(as_completed(futures), total=len(batch_files), desc=f\"Processing batch {i // batch_size + 1}\"):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    # Perbarui unpack\n",
    "                    texts, tables, images, pdf_id, elapsed_time = result\n",
    "                    all_texts.extend(texts)\n",
    "                    all_tables.extend(tables)\n",
    "                    all_images.extend(images) \n",
    "                    pdf_ids.append(pdf_id)\n",
    "                    processing_times.append(elapsed_time)\n",
    "    \n",
    "    # Perbarui nilai return\n",
    "    return all_texts, all_tables, all_images, pdf_ids, processing_times\n",
    "\n",
    "# Example usage\n",
    "input_dir = \"/path/to/pdf/directory\"\n",
    "output_dir = \"/path/to/output/directory\"\n",
    "\n",
    "# Process PDFs in batches\n",
    "# Perbarui unpack\n",
    "texts, tables, images, pdf_ids, processing_times = process_pdfs_in_batches(input_dir, output_dir)\n",
    "\n",
    "# Print processing times for each file\n",
    "for pdf_file, processing_time in zip(os.listdir(input_dir), processing_times):\n",
    "    print(f\"{pdf_file} processed in {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87383f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table summarization prompt\n",
    "table_prompt_text = \"\"\"You are an assistant tasked with summarizing tables. \\\n",
    "Give a concise summary of the table by forming logical and corresponding relationships rather than broad summaries. Table chunk: {element}\"\"\"\n",
    "table_prompt = ChatPromptTemplate.from_template(table_prompt_text)\n",
    "\n",
    "# Define the text summarization prompt\n",
    "text_prompt_text = \"\"\"You are an assistant tasked with summarizing text. \\\n",
    "Give a concise summary of the text chunk. Text chunk: {element}\"\"\"\n",
    "text_prompt = ChatPromptTemplate.from_template(text_prompt_text)\n",
    "\n",
    "# --- Prompt Peringkasan Gambar Baru ---\n",
    "def create_image_summarization_prompt(image_uri):\n",
    "    \"\"\"Creates a multimodal prompt for image summarization.\"\"\"\n",
    "    return [\n",
    "        SystemMessage(content=\"You are an expert assistant tasked with summarizing images from a research paper. Describe the key elements, data, methodology, and conclusions shown in this image. Be concise and accurate.\"),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please summarize this image from a research paper:\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_uri}}\n",
    "        ])\n",
    "    ]\n",
    "# --- Akhir Prompt Gambar ---\n",
    "\n",
    "\n",
    "# Create the model instance\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\") # Model ini sudah mendukung visi\n",
    "\n",
    "# Table summarization chain\n",
    "table_summarize_chain = {\"element\": lambda x: x} | table_prompt | model | StrOutputParser()\n",
    "\n",
    "# Text summarization chain\n",
    "text_summarize_chain = {\"element\": lambda x: x} | text_prompt | model | StrOutputParser()\n",
    "\n",
    "# --- Chain Peringkasan Gambar Baru ---\n",
    "image_summarize_chain = (\n",
    "    RunnableLambda(lambda x: create_image_summarization_prompt(x[\"element\"]))\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "# --- Akhir Chain Gambar ---\n",
    "\n",
    "def summarize_tables(tables, max_concurrency=5):\n",
    "    \"\"\"\n",
    "    Process the tables and generate summaries.\n",
    "    \n",
    "    Args:\n",
    "        tables (list): A list of Document objects containing table content.\n",
    "        max_concurrency (int): The maximum number of concurrent requests.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of table summaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # PERBAIKAN: Gunakan .page_content untuk mengakses string dari objek Document\n",
    "        table_summaries = table_summarize_chain.batch(\n",
    "            [table.page_content for table in tables], \n",
    "            {\"max_concurrency\": max_concurrency}\n",
    "        )\n",
    "        return table_summaries\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing tables: {e}\")\n",
    "        return []\n",
    "\n",
    "def summarize_texts(texts, max_concurrency=5):\n",
    "    \"\"\"\n",
    "    Process the texts and generate summaries.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): A list of Document objects containing text chunks.\n",
    "        max_concurrency (int): The maximum number of concurrent requests.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of text summaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # PERBAIKAN: Gunakan .page_content untuk mengakses string dari objek Document\n",
    "        text_summaries = text_summarize_chain.batch(\n",
    "            [text.page_content for text in texts], \n",
    "            {\"max_concurrency\": max_concurrency}\n",
    "        )\n",
    "        return text_summaries\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing texts: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Fungsi Peringkasan Gambar Baru ---\n",
    "def summarize_images(images, max_concurrency=5):\n",
    "    \"\"\"\n",
    "    Process the images and generate summaries.\n",
    "    \n",
    "    Args:\n",
    "        images (list): A list of Document objects containing image base64 URIs.\n",
    "        max_concurrency (int): The maximum number of concurrent requests.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of image summaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Gunakan .page_content (yang berisi URI base64) dan kirim sebagai dict ke chain\n",
    "        image_summaries = image_summarize_chain.batch(\n",
    "            [{\"element\": image.page_content} for image in images], \n",
    "            {\"max_concurrency\": max_concurrency}\n",
    "        )\n",
    "        return image_summaries\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing images: {e}\")\n",
    "        return []\n",
    "# --- Akhir Fungsi Gambar ---\n",
    "\n",
    "\n",
    "# Assuming `tables`, `texts`, and `images` are already obtained\n",
    "# Get table summaries\n",
    "table_summaries = summarize_tables(tables, max_concurrency=5)\n",
    "\n",
    "# Get text summaries\n",
    "text_summaries = summarize_texts(texts, max_concurrency=5)\n",
    "\n",
    "# --- Dapatkan Peringkasan Gambar ---\n",
    "image_summaries = summarize_images(images, max_concurrency=5)\n",
    "# --- --- --- --- --- --- --- ---\n",
    "\n",
    "# Print the summaries\n",
    "for i, table_summary in enumerate(table_summaries):\n",
    "    print(f\"Table {i+1} Summary: {table_summary}\")\n",
    "\n",
    "for i, text_summary in enumerate(text_summaries):\n",
    "    print(f\"Text {i+1} Summary: {text_summary}\")\n",
    "\n",
    "# --- Cetak Peringkasan Gambar ---\n",
    "for i, image_summary in enumerate(image_summaries):\n",
    "    print(f\"Image {i+1} Summary: {image_summary}\")\n",
    "# --- --- --- --- --- --- --- ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set persistent directory\n",
    "persist_directory = ''  # Specify your persistent directory here\n",
    "\n",
    "# Initialize the Chroma vector store with OpenAI embeddings\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings(), persist_directory=persist_directory)\n",
    "vectorstore.persist()\n",
    "\n",
    "# Create an in-memory document store\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Create the MultiVectorRetriever for handling vector and document retrieval\n",
    "MultiVector_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 10}  # Adjust the number of results to return from the search\n",
    ")\n",
    "\n",
    "# Function to add documents (text or tables) with summaries to the retriever\n",
    "def add_documents_to_retriever(contents, summaries, documents_type='text'):\n",
    "    \"\"\"\n",
    "    Adds text, table, or image documents along with summaries to the vector store and document store.\n",
    "\n",
    "    Args:\n",
    "        contents (list): A list of Document objects (text, table, or image).\n",
    "        summaries (list): A list of summaries corresponding to the documents.\n",
    "        documents_type (str): The type of document being added ('text', 'table', or 'image').\n",
    "    \"\"\"\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in contents]\n",
    "    \n",
    "    # Create the documents with content and metadata\n",
    "    documents = [\n",
    "        Document(\n",
    "            # PERBAIKAN: Gunakan content.page_content\n",
    "            page_content=content.page_content, \n",
    "            metadata={\n",
    "                id_key: doc_ids[i],\n",
    "                # PERBAIKAN: Gunakan content.metadata\n",
    "                \"pdf_id\": content.metadata[\"pdf_id\"], \n",
    "                \"summary\": summaries[i]\n",
    "                # Anda mungkin ingin menambahkan metadata lain dari 'content.metadata' di sini\n",
    "            }\n",
    "        )\n",
    "        for i, content in enumerate(contents)\n",
    "    ]\n",
    "    \n",
    "    # Add documents to the vector store and docstore\n",
    "    MultiVector_retriever.vectorstore.add_documents(documents)\n",
    "    # PERBAIKAN: Gunakan list comprehension dengan .page_content\n",
    "    MultiVector_retriever.docstore.mset(list(zip(doc_ids, [content.page_content for content in contents])))\n",
    "\n",
    "# Add text and table documents to the retriever\n",
    "add_documents_to_retriever(texts, text_summaries, documents_type='text')\n",
    "add_documents_to_retriever(tables, table_summaries, documents_type='table')\n",
    "# --- Tambahkan Gambar ke Retriever ---\n",
    "add_documents_to_retriever(images, image_summaries, documents_type='image')\n",
    "# --- --- --- --- --- --- --- ---\n",
    "\n",
    "# Set the search type to MMR (Maximum Margin Retrieval)\n",
    "MultiVector_retriever.search_type = SearchType.mmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b873b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique IDs for each text and table\n",
    "text_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "image_ids = [str(uuid.uuid4()) for _ in images] \n",
    "\n",
    "# Initialize mappings for content and summaries\n",
    "id_to_content = {}\n",
    "id_to_summary = {}\n",
    "\n",
    "# Build the mapping for texts\n",
    "for i, text in enumerate(texts):\n",
    "    text_id = text_ids[i]\n",
    "    id_to_content[text_id] = text.page_content # PERBAIKAN: Gunakan .page_content\n",
    "    id_to_summary[text_id] = text_summaries[i]\n",
    "\n",
    "# Build the mapping for tables\n",
    "for i, table in enumerate(tables):\n",
    "    table_id = table_ids[i]\n",
    "    id_to_content[table_id] = table.page_content # PERBAIKAN: Gunakan .page_content\n",
    "    id_to_summary[table_id] = table_summaries[i]\n",
    "\n",
    "# --- Tambahkan Pemetaan Gambar (Hanya Ringkasan) ---\n",
    "# Build the mapping for images\n",
    "for i, image in enumerate(images):\n",
    "    image_id = image_ids[i]\n",
    "    # KITA TIDAK menambahkan image.page_content (base64) ke id_to_content\n",
    "    # karena itu adalah 'sampah' untuk pencarian teks BM25.\n",
    "    id_to_summary[image_id] = image_summaries[i]\n",
    "# --- --- --- --- --- --- --- ---\n",
    "\n",
    "# Combine original content and summaries for BM25 input\n",
    "combined_texts_with_ids = []\n",
    "# Tambahkan teks dan tabel (konten + ringkasan)\n",
    "for content_id in id_to_content.keys():\n",
    "    combined_texts_with_ids.append((content_id, id_to_content[content_id]))  \n",
    "    combined_texts_with_ids.append((content_id, id_to_summary[content_id]))  \n",
    "\n",
    "# --- Tambahkan Ringkasan Gambar (Hanya Ringkasan) ---\n",
    "for image_id in image_ids:\n",
    "    if image_id in id_to_summary: # Pastikan ringkasan ada\n",
    "        combined_texts_with_ids.append((image_id, id_to_summary[image_id])) \n",
    "# --- --- --- --- --- --- --- ---\n",
    "\n",
    "# Initialize BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    [text for _, text in combined_texts_with_ids], k=10  # Top 10 results\n",
    ")\n",
    "\n",
    "# Initialize the EnsembleRetriever with BM25 and MultiVector retrievers\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, MultiVector_retriever], weights=[0.3, 1]\n",
    ")\n",
    "\n",
    "# Function to handle retrieval and ranking using EnsembleRetriever\n",
    "def retrieve_with_ensemble(query, k=10):\n",
    "    \"\"\"\n",
    "    Retrieves documents using the ensemble of retrievers (BM25 and MultiVector).\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to use for retrieval.\n",
    "        k (int): The number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        List of documents retrieved based on the ensemble search.\n",
    "    \"\"\"\n",
    "    return ensemble_retriever.retrieve(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1653f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# LLM\n",
    "# Ganti model ke model visi\n",
    "model = ChatOpenAI(temperature = 0, model = \"gpt-4o-mini\")\n",
    "\n",
    "def create_multimodal_prompt(input_dict):\n",
    "    \"\"\"\n",
    "    Membuat prompt multimodal (teks dan gambar) secara dinamis\n",
    "    berdasarkan konteks yang diambil dan pertanyaan.\n",
    "    \"\"\"\n",
    "    # create_documents sekarang mengembalikan string (teks, tabel, atau data:image URI)\n",
    "    context_docs = input_dict[\"context\"] \n",
    "    question = input_dict[\"question\"]\n",
    "    \n",
    "    # System prompt\n",
    "    system_message = SystemMessage(\n",
    "        content=\"Answer the question based only on the following context, which can include text, tables, and images:\"\n",
    "    )\n",
    "    \n",
    "    # Membangun konten untuk HumanMessage\n",
    "    user_content = []\n",
    "    \n",
    "    # Mulai dengan pertanyaan\n",
    "    user_content.append({\"type\": \"text\", \"text\": f\"Question: {question}\\n\\nContext:\"})\n",
    "    \n",
    "    # Tambahkan dokumen konteks (teks dan gambar)\n",
    "    text_buffer = []\n",
    "    for doc_content in context_docs:\n",
    "        if isinstance(doc_content, str) and doc_content.startswith(\"data:image\"):\n",
    "            # Jika ada teks di buffer, tambahkan dulu\n",
    "            if text_buffer:\n",
    "                user_content.append({\"type\": \"text\", \"text\": \"\\n---\\n\".join(text_buffer)})\n",
    "                text_buffer = []\n",
    "            \n",
    "            # Tambahkan gambar\n",
    "            user_content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": doc_content}\n",
    "            })\n",
    "        elif isinstance(doc_content, str):\n",
    "            # Tambahkan teks ke buffer\n",
    "            text_buffer.append(doc_content)\n",
    "    \n",
    "    # Tambahkan sisa teks di buffer\n",
    "    if text_buffer:\n",
    "        user_content.append({\"type\": \"text\", \"text\": \"\\n---\\n\".join(text_buffer)})\n",
    "        \n",
    "    user_message = HumanMessage(content=user_content)\n",
    "    \n",
    "    return [system_message, user_message]\n",
    "\n",
    "\n",
    "# Chain baru yang menggunakan prompt multimodal\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(create_original_query) | RunnableLambda(create_documents), \n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | RunnableLambda(create_multimodal_prompt)  # Menggunakan fungsi baru untuk membuat prompt\n",
    "    | model  \n",
    "    | StrOutputParser()  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3acc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms.base import LangchainLLMWrapper\n",
    "from langchain_community.chat_models import ChatOpenAI  # Modify import\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    RubricsScoreWithReference,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "# Create Langchain LLM instance\n",
    "# GANTI MODEL di sini ke model visi\n",
    "langchain_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Wrap the Langchain LLM instance in LangchainLLMWrapper\n",
    "wrapped_llm = LangchainLLMWrapper(langchain_llm)\n",
    "\n",
    "# Define custom rubrics\n",
    "my_custom_rubrics = {\n",
    "    \"score1_description\": \"The response is incorrect, irrelevant, or does not align with the ground truth.\",\n",
    "    \"score2_description\": \"The response partially matches the ground truth but includes significant errors, omissions, or irrelevant information.\",\n",
    "    \"score3_description\": \"The response generally aligns with the ground truth but may lack detail, clarity, or have minor inaccuracies.\",\n",
    "    \"score4_description\": \"The response is mostly accurate and aligns well with the ground truth, with only minor issues or missing details.\",\n",
    "    \"score5_description\": \"The response is fully accurate, aligns completely with the ground truth, and is clear and detailed.\",\n",
    "}\n",
    "\n",
    "# Use the dataset you previously constructed\n",
    "# dataset = Dataset.from_dict(data)  # Constructed earlier\n",
    "\n",
    "# Instantiate the metric class\n",
    "metric_with_ref = RubricsScoreWithReference(rubrics=my_custom_rubrics)\n",
    "\n",
    "# Perform the evaluation on the dataset\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "            metric_with_ref,\n",
    "            context_precision,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_recall,\n",
    "            answer_correctness,\n",
    "            answer_similarity\n",
    "        ],\n",
    "        llm=wrapped_llm  # Use the wrapped (vision-capable) LLM for evaluation\n",
    "    )\n",
    "    # Print the evaluation results\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatrag",
   "language": "python",
   "name": "chatrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
